Алгоритм, который полагает, что все переменные в наборе данных не коррелируют друг с другом (являются наивными).
Основан на сопоставлении свойств объекта с классами.
# Теорема Байеса
$$
P(y = c|x) = \frac {P(x|y = c) P(y = c)} {P(x)}
$$
Алгоритм хорошо справляется с категорийными признаками
Применяется для составления прогнозов в реальном времени, многоклассового прогнозирования, системы рекомендаций, фильтрация текста
# Теорема Байеса и классификация
Цель классификации - понять, к какому классу принадлежит объект X. Необходимо найти наиболее вероятный класс для этого объекта.
Классификатор представляет объект, как набор независимых признаков.
Вероятность принадлежности объекта классу находится перемножением вероятностей принадлежности признаков этому классу.
При таком перемножении могут получится довольно маленькие значения, так что 
есть альтернативная формула расчёта с помощью логарифма
## Формула Наивного Байеса
$$
P(C | X) = \frac{P(X | C) * P(C)} {P(X)}
$$
Где:
- **P(C | X)** - Апостериорная вероятность: Вероятность того, что объект принадлежит классу `C` при условии, что мы наблюдаем признаки `X`. Это то, что мы хотим вычислить.
- **P(X | C)** - Вероятность правдоподобия (likelihood): Вероятность наблюдения признаков `X` при условии, что объект принадлежит классу `C`.
- **P(C)** - Априорная вероятность: Вероятность того, что объект принадлежит классу `C` до наблюдения признаков. Обычно оценивается как доля объектов класса `C` в обучающей выборке.
- **P(X)** - Вероятность свидетельства: Вероятность наблюдения признаков `X` (независимо от класса). В задачах классификации, где мы просто сравниваем вероятности для разных классов, часто опускается, так как она одинакова для всех классов и не влияет на результат сравнения.
## **Наивность (Независимость признаков):**

“Наивность” этого классификатора заключается в предположении, что все признаки независимы друг от друга при условии класса. Это означает, что вероятность наблюдения всех признаков `X = (x1, x2, ..., xn)` при условии класса `C` можно разложить на произведение вероятностей каждого признака:

$$
P(X | C) = P(x1 | C) * P(x2 | C) * ... * P(xn | C)
$$